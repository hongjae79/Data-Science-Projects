{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_core = df_train[['airline_sentiment', 'text']]\n",
    "df_train_core_without_nan = df_train_core.drop([3338])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_core_without_nan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f83f5ee2a736>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbig_list2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train_core_without_nan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0meach_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train_core_without_nan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbig_list2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbig_list2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0meach_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train_core_without_nan' is not defined"
     ]
    }
   ],
   "source": [
    "big_list = []\n",
    "\n",
    "for i in range(len(df_train_core_without_nan)):\n",
    "    each_list = df_train_core_without_nan.text[i].split()\n",
    "    big_list = big_list2 + each_list\n",
    "\n",
    "word_count = Counter(big_list)\n",
    "word_count_most_common = word_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_list = []\n",
    "\n",
    "for j in range(len(word_count_most_common)):\n",
    "    \n",
    "    total_count = 0 \n",
    "    positive_count = 0 \n",
    "    neutral_count = 0 \n",
    "    negative_count = 0 \n",
    "    word = word_count_most_common[j][0]\n",
    "    row = []\n",
    "    \n",
    "    for i in range(len(df_train_core_without_nan)):\n",
    "        list1 = df_train_core_without_nan.text[i].split()\n",
    "        if word in list1:\n",
    "            total_count = total_count + 1\n",
    "        if word in list1 and df_train_core_without_nan.airline_sentiment[i] == 'positive':\n",
    "            positive_count = positive_count + 1\n",
    "        if word in list1 and df_train_core_without_nan.airline_sentiment[i] == 'neutral':\n",
    "            neutral_count = neutral_count + 1\n",
    "        if word in list1 and df_train_core_without_nan.airline_sentiment[i] == 'negative':\n",
    "            negative_count = negative_count + 1\n",
    "    row.append(word)\n",
    "    row.append(total_count)\n",
    "    row.append(positive_count)\n",
    "    row.append(neutral_count)\n",
    "    row.append(negative_count)\n",
    "    row.append(positive_count/total_count)\n",
    "    row.append(neutral_count/total_count)\n",
    "    row.append(negative_count/total_count)\n",
    "    \n",
    "    big_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['word', 'total_count', 'positive_count', 'neutral_count', 'negative_count', 'pos_prob', 'neu_prob', 'neg_prob']\n",
    "df_train_analyzed = pd.DataFrame.from_records(big_list, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggest(x, y, z):\n",
    "    \n",
    "    Max = x\n",
    "    status = 'positive'\n",
    "    if y > Max:\n",
    "        Max = y   \n",
    "        status = 'neutral'\n",
    "    if z > Max:\n",
    "        Max = z\n",
    "        status = 'negative'\n",
    "        if y > z:\n",
    "            Max = y\n",
    "            status = 'neutral'\n",
    "    return Max, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_analyzed_rescaled = df_train_analyzed.copy()\n",
    "\n",
    "e = 2\n",
    "\n",
    "df_train_analyzed_rescaled['pos_prob'] = df_train_analyzed_rescaled['pos_prob'].apply(lambda x : pow(x, 1/e + 1/6))\n",
    "df_train_analyzed_rescaled['neu_prob'] = df_train_analyzed_rescaled['neu_prob'].apply(lambda x : pow(x, 1/(2*e + 1/6)))\n",
    "df_train_analyzed_rescaled['neg_prob'] = df_train_analyzed_rescaled['neg_prob'].apply(lambda x : pow(x, e + 1/6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  0.9742360695026963\n"
     ]
    }
   ],
   "source": [
    "c = 0 \n",
    "\n",
    "for j in range(len(df_train_core_without_nan)):\n",
    "\n",
    "    list2 = df_train_core_without_nan.text[j].split()\n",
    "    list2_to_pd = []\n",
    "    df_sentence = []\n",
    "\n",
    "    for i in range(len(list2)):\n",
    "        word2 = list2[i]\n",
    "        a = df_train_analyzed_rescaled.loc[df_train_analyzed_rescaled['word'] == word2]\n",
    "        b = a[['word', 'pos_prob', 'neu_prob', 'neg_prob']].values.tolist()\n",
    "        list2_to_pd.append(b[0])\n",
    "\n",
    "    df_sentence = pd.DataFrame(list2_to_pd, columns =['word', 'pos_prob', 'neu_prob', 'neg_prob'] )\n",
    "    k = biggest(df_sentence['pos_prob'].max(), df_sentence['neu_prob'].max(), df_sentence['neg_prob'].max())\n",
    "    if k[1] == df_train_core_without_nan.airline_sentiment[j]:\n",
    "        c = c + 1\n",
    "        \n",
    "print('accuracy is ', c/len(df_train_core_without_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_core = df_test['text']\n",
    "big_list = []\n",
    "\n",
    "for i in range(len(df_test_core)):\n",
    "    each_list = df_test_core[i].split()\n",
    "    big_list = big_list + each_list\n",
    "\n",
    "word_count = Counter(big_list)\n",
    "word_count_most_common = word_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(824):\n",
    "    index.append(10911 + i)\n",
    "\n",
    "labels = ['word', 'total_count', 'positive_count', 'neutral_count', 'negative_count', 'pos_prob', 'neu_prob', 'neg_prob']\n",
    "big_list = []\n",
    "s = set(df_train_analyzed['word'])\n",
    "c = 0 \n",
    "for i in range(len(word_count_most_common)):\n",
    "    if word_count_most_common[i][0] not in s:\n",
    "        list3 = []\n",
    "        list3.append(word_count_most_common[i][0])\n",
    "        for j in range(7):\n",
    "            list3.append(0.0)\n",
    "        big_list.append(list3)\n",
    "        \n",
    "df_big_list = pd.DataFrame(big_list, columns = labels, index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test_combined = pd.concat([df_train_analyzed_rescaled, df_big_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0 \n",
    "labels = ['tweet_id', 'airline_sentiment']\n",
    "big_result = []\n",
    "\n",
    "for j in range(len(df_test_core)):\n",
    "\n",
    "    list2 = df_test_core[j].split()\n",
    "    list2_to_pd = []\n",
    "    df_sentence = []\n",
    "    result = []   \n",
    "\n",
    "    for i in range(len(list2)):\n",
    "        word2 = list2[i]\n",
    "        a = df_train_test_combined.loc[df_train_test_combined['word'] == word2]\n",
    "        b = a[['word', 'pos_prob', 'neu_prob', 'neg_prob']].values.tolist()\n",
    "        list2_to_pd.append(b[0])\n",
    "\n",
    "    df_sentence = pd.DataFrame(list2_to_pd, columns =['word', 'pos_prob', 'neu_prob', 'neg_prob'] )\n",
    "    k = biggest(df_sentence['pos_prob'].max(), df_sentence['neu_prob'].max(), df_sentence['neg_prob'].max())\n",
    "    \n",
    "    result.append(df_test.tweet_id[j])\n",
    "    result.append(k[1])\n",
    "\n",
    "    big_result.append(result)\n",
    "\n",
    "df_submission = pd.DataFrame(big_result, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('output1.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>total_count</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>neutral_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>pos_prob</th>\n",
       "      <th>neu_prob</th>\n",
       "      <th>neg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@united</td>\n",
       "      <td>2708.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>0.261441</td>\n",
       "      <td>0.666039</td>\n",
       "      <td>0.436967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>0.245396</td>\n",
       "      <td>0.668447</td>\n",
       "      <td>0.450013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>0.294769</td>\n",
       "      <td>0.634828</td>\n",
       "      <td>0.446697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>854.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>0.248828</td>\n",
       "      <td>0.684500</td>\n",
       "      <td>0.419629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>866.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>0.217759</td>\n",
       "      <td>0.647955</td>\n",
       "      <td>0.512313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  total_count  positive_count  neutral_count  negative_count  \\\n",
       "0  @united       2708.0           362.0          498.0          1848.0   \n",
       "1       to       1382.0           168.0          258.0           956.0   \n",
       "2      the       1056.0           169.0          159.0           728.0   \n",
       "3        I        854.0           106.0          176.0           572.0   \n",
       "4        a        866.0            88.0          142.0           636.0   \n",
       "\n",
       "   pos_prob  neu_prob  neg_prob  \n",
       "0  0.261441  0.666039  0.436967  \n",
       "1  0.245396  0.668447  0.450013  \n",
       "2  0.294769  0.634828  0.446697  \n",
       "3  0.248828  0.684500  0.419629  \n",
       "4  0.217759  0.647955  0.512313  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_core_without_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_sentiment_numeric = []\n",
    "\n",
    "for i in range(len(df_train_core_without_nan)):\n",
    "    if df_train_core_without_nan.airline_sentiment[i] == 'negative':\n",
    "        airline_sentiment_numeric.append(-1)\n",
    "    if df_train_core_without_nan.airline_sentiment[i] == 'neutral':\n",
    "        airline_sentiment_numeric.append(0)\n",
    "    else:\n",
    "        airline_sentiment_numeric.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_sentiment                                               text\n",
       "0                  0                @VirginAmerica What @dhepburn said.\n",
       "1                  1  @VirginAmerica plus you've added commercials t...\n",
       "2                  0  @VirginAmerica I didn't today... Must mean I n...\n",
       "3                 -1  @VirginAmerica it's really aggressive to blast...\n",
       "4                 -1  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_core_without_nan_and_numeric = df_train_core_without_nan.copy()\n",
    "\n",
    "df_train_core_without_nan_and_numeric['airline_sentiment'] = df_train_core_without_nan_and_numeric['airline_sentiment'].apply(\n",
    "{'negative':-1, 'neutral':0, 'positive': 1}.get)\n",
    "\n",
    "df_train_core_without_nan_and_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0 \n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for j in range(len(df_train_core_without_nan_and_numeric)):\n",
    "\n",
    "    list2 = df_train_core_without_nan_and_numeric.text[j].split()\n",
    "    list2_to_pd = []\n",
    "    df_sentence = []\n",
    "    list3 = []\n",
    "\n",
    "    for i in range(len(list2)):\n",
    "        word2 = list2[i]\n",
    "        a = df_train_analyzed_rescaled.loc[df_train_analyzed_rescaled['word'] == word2]\n",
    "        b = a[['word', 'pos_prob', 'neu_prob', 'neg_prob']].values.tolist()\n",
    "        list2_to_pd.append(b[0])\n",
    "\n",
    "    df_sentence = pd.DataFrame(list2_to_pd, columns =['word', 'pos_prob', 'neu_prob', 'neg_prob'] )\n",
    "    list3.append(df_sentence['pos_prob'].max())\n",
    "    list3.append(df_sentence['neu_prob'].max())\n",
    "    list3.append(df_sentence['neg_prob'].max())\n",
    "    \n",
    "    train_images.append(list3)\n",
    "    train_labels.append(df_train_core_without_nan_and_numeric.airline_sentiment[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_images = pd.DataFrame(train_images)\n",
    "train_images_to_array = df_train_images.as_matrix(columns=None).astype(np.float)\n",
    "\n",
    "df_train_labels = pd.DataFrame(train_labels)\n",
    "train_labels_to_array = np.array(df_train_labels[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try different classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_core = pd.DataFrame(df_test_core)\n",
    "\n",
    "c = 0 \n",
    "\n",
    "test_images = []\n",
    "\n",
    "for j in range(len(df_test_core)):\n",
    "\n",
    "    list2 = df_test_core.text[j].split()\n",
    "    list2_to_pd = []\n",
    "    df_sentence = []\n",
    "    list3 = []\n",
    "\n",
    "    for i in range(len(list2)):\n",
    "        word2 = list2[i]\n",
    "        a = df_train_test_combined.loc[df_train_test_combined['word'] == word2]\n",
    "        b = a[['word', 'pos_prob', 'neu_prob', 'neg_prob']].values.tolist()\n",
    "        list2_to_pd.append(b[0])\n",
    "\n",
    "    df_sentence = pd.DataFrame(list2_to_pd, columns =['word', 'pos_prob', 'neu_prob', 'neg_prob'] )\n",
    "    list3.append(df_sentence['pos_prob'].max())\n",
    "    list3.append(df_sentence['neu_prob'].max())\n",
    "    list3.append(df_sentence['neg_prob'].max())\n",
    "    \n",
    "    test_images.append(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = pd.DataFrame(test_images)\n",
    "\n",
    "test_images_to_array = test_images.as_matrix(columns=None).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( train_images_to_array, train_labels_to_array,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 668 points : 10\n",
      "Accuracy is  0.9850299401197605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_pred).sum()))\n",
    "print(\"Accuracy is \",  (y_test == y_pred).sum() / X_test.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = df_test['tweet_id'].tolist()\n",
    "y_pred = clf.fit(X_train, y_train).predict(test_images_to_array)\n",
    "labels = ['tweet_id', 'airline_sentiment']\n",
    "d = {'airline_sentiment': y_pred, 'tweet_id': col1}\n",
    "df = pd.DataFrame(data=d)\n",
    "df = df.reindex(columns=labels)\n",
    "df['airline_sentiment'] = df['airline_sentiment'].apply({-1 : 'negative', 0:'neutral', 1:'positive' }.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('outputNB.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 668 points : 12\n",
      "Accuracy is  0.9820359281437125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_pred).sum()))\n",
    "print(\"Accuracy is \",  (y_test == y_pred).sum() / X_test.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = df_test['tweet_id'].tolist()\n",
    "y_pred = clf.fit(X_train, y_train).predict(test_images_to_array)\n",
    "labels = ['tweet_id', 'airline_sentiment']\n",
    "d = {'airline_sentiment': y_pred, 'tweet_id': col1}\n",
    "df = pd.DataFrame(data=d)\n",
    "df = df.reindex(columns=labels)\n",
    "df['airline_sentiment'] = df['airline_sentiment'].apply({-1 : 'negative', 0:'neutral', 1:'positive' }.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('outputKNN.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 668 points : 12\n",
      "Accuracy is  0.9820359281437125\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_pred).sum()))\n",
    "print(\"Accuracy is \",  (y_test == y_pred).sum() / X_test.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = df_test['tweet_id'].tolist()\n",
    "y_pred = clf.fit(X_train, y_train).predict(test_images_to_array)\n",
    "labels = ['tweet_id', 'airline_sentiment']\n",
    "d = {'airline_sentiment': y_pred, 'tweet_id': col1}\n",
    "df = pd.DataFrame(data=d)\n",
    "df = df.reindex(columns=labels)\n",
    "df['airline_sentiment'] = df['airline_sentiment'].apply({-1 : 'negative', 0:'neutral', 1:'positive' }.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('outputSVM.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 668 points : 15\n",
      "Accuracy is  0.9775449101796407\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_pred).sum()))\n",
    "print(\"Accuracy is \",  (y_test == y_pred).sum() / X_test.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = df_test['tweet_id'].tolist()\n",
    "y_pred = clf.fit(X_train, y_train).predict(test_images_to_array)\n",
    "labels = ['tweet_id', 'airline_sentiment']\n",
    "d = {'airline_sentiment': y_pred, 'tweet_id': col1}\n",
    "df = pd.DataFrame(data=d)\n",
    "df = df.reindex(columns=labels)\n",
    "df['airline_sentiment'] = df['airline_sentiment'].apply({-1 : 'negative', 0:'neutral', 1:'positive' }.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('outputDT.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 668 points : 18\n",
      "Accuracy is  0.9730538922155688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_pred).sum()))\n",
    "print(\"Accuracy is \",  (y_test == y_pred).sum() / X_test.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = df_test['tweet_id'].tolist()\n",
    "y_pred = clf.fit(X_train, y_train).predict(test_images_to_array)\n",
    "labels = ['tweet_id', 'airline_sentiment']\n",
    "d = {'airline_sentiment': y_pred, 'tweet_id': col1}\n",
    "df = pd.DataFrame(data=d)\n",
    "df = df.reindex(columns=labels)\n",
    "df['airline_sentiment'] = df['airline_sentiment'].apply({-1 : 'negative', 0:'neutral', 1:'positive' }.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('outputRF.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 3 # MNIST data input (img shape: 28*28)\n",
    "n_hidden_1 = 2 # 1st layer number of neurons\n",
    "n_hidden_2 = 1 # 2nd layer number of neurons\n",
    "num_classes = 3 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train to one hot vetor\n",
    "\n",
    "depth = 3\n",
    "y_train_one_hot = tf.one_hot(y_train, depth)\n",
    "y_train_one_hot_np_array = tf.Session().run(y_train_one_hot)\n",
    "\n",
    "y_test_one_hot = tf.one_hot(y_test, depth)\n",
    "y_test_one_hot_np_array = tf.Session().run(y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batches(X_train, y_train, batch_size):\n",
    "    r = np.random.permutation(len(X_train))[:batch_size]\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        batch_x.append(X_train[r[i]])\n",
    "        batch_y.append(y_train[r[i]])\n",
    "        \n",
    "    return batch_x, batch_y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 0.2649, Training Accuracy= 0.141\n",
      "Step 100, Minibatch Loss= 29.8390, Training Accuracy= 0.000\n",
      "Step 200, Minibatch Loss= 172.8518, Training Accuracy= 0.000\n",
      "Step 300, Minibatch Loss= 465.0149, Training Accuracy= 0.000\n",
      "Step 400, Minibatch Loss= 259.9980, Training Accuracy= 0.852\n",
      "Step 500, Minibatch Loss= 70.0684, Training Accuracy= 0.875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.8338323\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mini_batches(X_train, y_train_one_hot_np_array, batch_size)\n",
    "        \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "         \n",
    "        \n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y})\n",
    "            \n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "        \n",
    "        \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "          sess.run(accuracy, feed_dict={X: X_test, Y: y_test_one_hot_np_array}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b1': <tf.Variable 'Variable_3:0' shape=(2,) dtype=float32_ref>,\n",
       " 'b2': <tf.Variable 'Variable_4:0' shape=(1,) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable_5:0' shape=(3,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,weights) + biases)\n",
    "\n",
    "feed_dict = {x: [your_image]}\n",
    "classification = tf.run(y, feed_dict)\n",
    "print classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
